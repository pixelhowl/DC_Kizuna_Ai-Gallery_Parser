{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UFUzUnI4N1NKOVdTd3gyeVU3UzBQRDQ4RmVRTWhhNzBKV3gvRXh5OUExTT0='"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install g++ openjdk-8-jdk openjdk-8-jre \n",
    "!pip install pandas numpy tqdm jnius gevent JPype1-py3 konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "utils.database.generate_db_directory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_page_num = 6649869\n",
    "end_page_num = 6815073\n",
    "\n",
    "utils.parsers.run_web_crawler(start_page_num,end_page_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "wordranker = utils.parsers.wordRanker(use_cache=False)\n",
    "wordranker.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-16 23:57:24,911][kizunaai][INFO] Using cached tags...\n",
      "[2022-11-16 23:57:29,171][kizunaai][INFO] Word cloud generated.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "wordranker = utils.parsers.wordRanker()\n",
    "wordranker.word_cloud()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dccon Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-16 23:57:34,984][kizunaai][INFO] Using cached tags...\n",
      "[2022-11-16 23:57:37,212][kizunaai][INFO] Finished.\n",
      "[2022-11-16 23:57:37,554][kizunaai][INFO] Finished.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "wordranker = utils.parsers.wordRanker()\n",
    "wordranker.dccon_rank()\n",
    "wordranker.dccon_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "youtuberanker = utils.parsers.youtubeCounter()\n",
    "youtuberanker.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont execute below cells. Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont execute below cells. Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont execute below cells. Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont execute below cells. Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from parsers import parser\n",
    "import vtuber_dict as vd\n",
    "import os\n",
    "from datetime import datetime\n",
    "gall = 'kizunaai';year=datetime.now().year; month =datetime.now().month-1 # 갤러리, 연, 월\n",
    "baseloc = os.path.abspath('./%s/%s/%s/' % (gall,year,month)) # 경로\n",
    "\n",
    "parser(baseloc, vd.nijisanji, 'sum_niji.csv')\n",
    "parser(baseloc, vd.hololive, 'sum_holo.csv')\n",
    "parser(baseloc, vd.vtuber, 'sum_ai.csv')\n",
    "parser(baseloc, vd.exceptholo, 'sum_noholo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import vtuber_dict as vd\n",
    "import word_dict as wd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# df[df['col'].str.contains(\"hello|train\",na=False)]\n",
    "\n",
    "first = str(year)+'-'+str(month)\n",
    "last = str(year)+'-'+str(month+1) if month != 12 else str(year+1)+'-1'\n",
    "vtuber_dict=vd.vtuber\n",
    "word_dict=wd.word_dict\n",
    "total_col=['Vtuber','관련 글/댓글 수']\n",
    "\n",
    "for award in word_dict:\n",
    "    total_col.append(award)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    cont[\"제목내용\"]=cont[u'제목'].astype(str)+'\\n'+cont['content'].astype(str)\n",
    "except NameError as e:\n",
    "    idf = pd.read_json(baseloc+'post.json');cdf = pd.read_json(baseloc+'comment.json')\n",
    "    cdf=cdf[cdf['dccon']==False]\n",
    "    cont = pd.concat([idf, cdf],sort=False)\n",
    "    cont[\"제목내용\"]=cont[u'제목'].astype(str)+'\\n'+cont['content'].astype(str)\n",
    "    \n",
    "cont[\"제목내용\"]=cont[\"제목내용\"].str.replace(r'<[^<]+?>','',regex=True)\n",
    "total_info=[]\n",
    "total_percent_info=[]\n",
    "\n",
    "reader_path=baseloc+'/sum_ai.csv'\n",
    "df = pd.read_csv(reader_path, index_col=0)\n",
    "target_vtuber=df[\"Vtuber\"].values\n",
    "count_tags_keys = count_tags.keys()\n",
    "for vtuber in tqdm(target_vtuber):\n",
    "    award_col=[vtuber]\n",
    "    award_percent_col=[vtuber]\n",
    "    fillters=''\n",
    "    \n",
    "    for nickname in vtuber_dict[vtuber]:\n",
    "        fillters+= nickname+'|'\n",
    "    fillters=fillters[:-1]\n",
    "#     print(fillters)\n",
    "    vdtuer_df=cont[cont['제목내용'].str.contains(fillters,na=False, regex = True)][['제목내용']]\n",
    "#     print(vdtuer_df['제목내용'])\n",
    "    \n",
    "    vtuber_count = count_tags[vtuber] if vtuber in count_tags_keys else 0\n",
    "    award_col.append(vtuber_count)\n",
    "    award_percent_col.append(vtuber_count)\n",
    "    for award in word_dict:\n",
    "        award_fillters=''\n",
    "        for word in word_dict[award]:\n",
    "            award_fillters+= word+'|'\n",
    "        award_fillters=award_fillters[:-1]\n",
    "#         print(award_fillters)\n",
    "        award_df=vdtuer_df[vdtuer_df['제목내용'].str.contains(award_fillters,na=False, regex = True)]\n",
    "        award_count=len(award_df)\n",
    "#         print(award_df['제목내용'])\n",
    "        if award_count == 0 or vtuber_count == 0:\n",
    "            award_percent_col.append(0)\n",
    "        else:\n",
    "            award_percent_col.append(award_count/vtuber_count*100)\n",
    "        award_col.append(award_df['제목내용'].count())\n",
    "#     print(award_fillters)\n",
    "    \n",
    "    total_info.append(award_col)\n",
    "    total_percent_info.append(award_percent_col)\n",
    "#     break\n",
    "    \n",
    "total_per_df = pd.DataFrame(total_percent_info, columns=total_col)\n",
    "total_per_df.to_csv(baseloc+'/award_percent.csv', sep=',', index=True)\n",
    "\n",
    "total_df = pd.DataFrame(total_info, columns=total_col)\n",
    "total_df.to_csv(baseloc+'/award.csv', sep=',', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import os \n",
    "\n",
    "old_month = month - 1\n",
    "old_year = year\n",
    "if month is 1:\n",
    "    old_month = 12\n",
    "    old_year = year - 1\n",
    "oldloc=os.path.abspath('./%s/%s/%s/' % (gall,old_year,old_month))\n",
    "\n",
    "\n",
    "# pd.read_csv(baseloc+\"/award.csv\")\n",
    "# for award in word_dict:\n",
    "#     print(f\"{award} Award\")\n",
    "#     print(total_df.sort_values(by=[award], ascending=False).head(n=1))\n",
    "    \n",
    "# pd.read_csv(baseloc+\"/award_percent.csv\")\n",
    "for award in tqdm(word_dict):\n",
    "    print(f\"{award} Award\")\n",
    "    total_per_df50 = total_per_df.sort_values(by=[\"관련 글/댓글 수\"], ascending=False).head(n=50)\n",
    "    print(total_per_df50.sort_values(by=[award], ascending=False).head(n=3))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename='commentpost_rank.csv'\n",
    "total_commentpost_df=total_per_df.sort_values(by=[\"관련 글/댓글 수\"], ascending=False)[[\"Vtuber\",\"관련 글/댓글 수\"]]\n",
    "\n",
    "total_commentpost_df.index = np.arange(1, len(total_commentpost_df) + 1)\n",
    "\n",
    "try:\n",
    "    old_data = pd.read_csv(os.path.join(oldloc, output_filename))\n",
    "except:\n",
    "    old_data = pd.DataFrame()\n",
    "compared_ranks = []\n",
    "for idx, member in tqdm(total_commentpost_df.iterrows(), total=len(total_commentpost_df)):\n",
    "    vtuber = member[\"Vtuber\"]\n",
    "    try:\n",
    "        old_rank = old_data[old_data[\"Vtuber\"] == vtuber].index[0]+1\n",
    "    except:\n",
    "        old_rank = \"NA\"\n",
    "\n",
    "    if old_rank == \"NA\":\n",
    "        compared_rank = f\"NEW\"\n",
    "    elif idx > old_rank:\n",
    "        compared_rank = f\"▼{idx-old_rank}\"\n",
    "    elif idx < old_rank:\n",
    "        compared_rank = f\"▲{old_rank-idx}\"\n",
    "    elif idx == old_rank:\n",
    "        compared_rank = f\"■-\"\n",
    "    else:\n",
    "        compared_rank=\"Error\"\n",
    "    compared_ranks.append(compared_rank)\n",
    "\n",
    "total_commentpost_df[\"전월 대비 순위\"]=compared_ranks\n",
    "total_commentpost_df.to_csv(baseloc+'/commentpost_rank.csv', sep=',', index=True)\n",
    "\n",
    "print(total_commentpost_df.head(n=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(total_commentpost_df[\"관련 글/댓글 수\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import urllib.parse as urlparse\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import ray\n",
    "ray.init()\n",
    "from gevent.pool import Pool\n",
    "\n",
    "# https://stackoverflow.com/questions/4356538/how-can-i-extract-video-id-from-youtubes-link-in-python\n",
    "def video_id_parse(value):\n",
    "    \"\"\"\n",
    "    Examples:\n",
    "    - http://youtu.be/SA2iWivDJiE\n",
    "    - http://www.youtube.com/watch?v=_oPAwA_Udwc&feature=feedu\n",
    "    - http://www.youtube.com/embed/SA2iWivDJiE\n",
    "    - http://www.youtube.com/v/SA2iWivDJiE?version=3&amp;hl=en_US\n",
    "    \"\"\"\n",
    "    \n",
    "    query = urlparse.urlparse(value)\n",
    "    if query.hostname == 'youtu.be':\n",
    "        return query.path[1:]\n",
    "    if query.hostname in ('www.youtube.com', 'youtube.com'):\n",
    "        if query.path == '/watch':\n",
    "            p = urlparse.parse_qs(query.query)\n",
    "            return p['v'][0]\n",
    "        if query.path[:7] == '/embed/':\n",
    "            return query.path.split('/')[2]\n",
    "        if query.path[:3] == '/v/':\n",
    "            return query.path.split('/')[2]\n",
    "    # fail?\n",
    "    return None\n",
    "\n",
    "gall = 'kizunaai';year=datetime.now().year; month =datetime.now().month-1 # 갤러리, 연, 월\n",
    "baseloc = os.path.abspath('./%s/%s/%s/' % (gall,year,month)) # 경로\n",
    "  # https://stackoverflow.com/questions/28292822/how-to-know-uploader-of-a-video-using-youtube-v3-api\n",
    "youtube_query='https://www.googleapis.com/youtube/v3/videos?fields=items(snippet(channelTitle))&part=snippet&id={YOUR_VIDEO_ID}&key={API_KEY}'\n",
    "# https://stackoverflow.com/questions/4705996/python-regex-convert-youtube-url-to-youtube-video/19161373\n",
    "# Regex\n",
    "yt_regex = r'(https?://)?(www\\.)?(youtube|youtu|youtube-nocookie)\\.(com|be)/(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})'\n",
    "\n",
    "columns=[\"ChannelName\", \"VideoID\", \"Count\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    cont[\"제목내용\"]=cont[u'제목'].astype(str)+'\\n'+cont['content'].astype(str)\n",
    "    yout_cont = cont[cont['제목내용'].str.contains(yt_regex, na=False, regex = True)][['제목내용']]\n",
    "except NameError as e:\n",
    "    idf = pd.read_json(baseloc+'post.json');cdf = pd.read_json(baseloc+'comment.json')\n",
    "    cdf=cdf[cdf['dccon']==False]\n",
    "    cont = pd.concat([idf, cdf],sort=False)\n",
    "    cont[\"제목내용\"]=cont[u'제목'].astype(str)+'\\n'+cont['content'].astype(str)\n",
    "    yout_cont = cont[cont['제목내용'].str.contains(yt_regex, na=False, regex = True)][['제목내용']]\n",
    "if os.path.isfile(baseloc+'/youtube.csv'):\n",
    "    yt_df=pd.read_csv(baseloc+'/youtube.csv',index_col=None)\n",
    "    yt_df[\"VideoID\"]=yt_df[\"VideoID\"].str.replace(r\"[가-힣|ㄱ-ㅎ|ㅏ-ㅣ ]+\",\"\",regex=True).str.replace(r\"(https://www.youtube.com/watch)|(https://m.youtube.com/watch)\",\"\",regex=True)\n",
    "    yt_df[\"Count\"]=0\n",
    "else:\n",
    "    yt_df=pd.DataFrame(columns=columns)\n",
    "\n",
    "yout_cont[\"제목내용\"]=yout_cont[\"제목내용\"].str.replace(r'<[^<]+?>','',regex=True)\n",
    "req_count=0\n",
    "NUM=0\n",
    "\n",
    "yt_regex_id = ray.put(yt_regex)\n",
    "@ray.remote\n",
    "def parse_contents(contents, yt_regex):\n",
    "    processed_video_ids = []\n",
    "    for content in contents:\n",
    "        content=str(content)\n",
    "        video_ids = [x.group() for x in re.finditer(yt_regex, content)]\n",
    "        \n",
    "        for raw_video_id in video_ids:\n",
    "            video_id = str(video_id_parse(str(raw_video_id)))\n",
    "            if video_id is None:\n",
    "                continue\n",
    "            video_id = video_id.replace(\"https://www.youtube.com/watch\",\"\").replace(\"https://m.youtube.com/watch\",\"\")\n",
    "            video_id = re.sub(r\"[가-힣|ㄱ-ㅎ|ㅏ-ㅣ ]+\",\"\",video_id)\n",
    "            processed_video_ids.append([video_id])\n",
    "            \n",
    "    return processed_video_ids\n",
    "\n",
    "result_ids=[]\n",
    "contents = []\n",
    "batch_size = 1000\n",
    "for idx, row in tqdm(yout_cont.iterrows(), total=len(yout_cont)):\n",
    "    content = row[\"제목내용\"]\n",
    "    contents.append(content)\n",
    "    if len(contents) >= batch_size:\n",
    "        result_ids.append(parse_contents.remote(contents, yt_regex_id))\n",
    "        contents=[]\n",
    "    \n",
    "with tqdm(total=len(result_ids)) as pbar: # 소요 시간 출력\n",
    "    yt_arr = []\n",
    "    while len(result_ids):\n",
    "        done_id, result_ids = ray.wait(result_ids)\n",
    "        test=ray.get(done_id)\n",
    "\n",
    "        video_ids = test[0]\n",
    "        yt_arr.extend(video_ids)\n",
    "        pbar.update(1)\n",
    "        \n",
    "raw_yt_df=pd.DataFrame(yt_arr, columns=[\"VideoID\"])\n",
    "raw_yt_df = raw_yt_df[raw_yt_df[\"VideoID\"] != \"None\"]\n",
    "yt_df=raw_yt_df.value_counts().to_frame(name=\"Count\")\n",
    "\n",
    "yt_df.sort_values(by=['Count'], ascending=False, inplace=True)\n",
    "yt_df.to_csv(baseloc+'/youtube.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unknown 재탐색\n",
    "yt_df=pd.read_csv(baseloc+'/youtube.csv',index_col=None)\n",
    "KEYS=[\"PUT_YOUR_API_KEY\"]\n",
    "\n",
    "@ray.remote\n",
    "def getChannelName(idx, video_id, key):\n",
    "    try:\n",
    "        youtube_info = requests.get(youtube_query.format(YOUR_VIDEO_ID=video_id, API_KEY=key)).json()\n",
    "        channel_name = youtube_info['items'][0]['snippet']['channelTitle']\n",
    "    except:\n",
    "        channel_name = \"Unknown\"\n",
    "    return idx, channel_name\n",
    "    \n",
    "req_count = 0\n",
    "NUM = 0\n",
    "result_ids = []\n",
    "for idx, row in tqdm(yt_df.iterrows(), total=len(yt_df)):\n",
    "    channel_name=str(row[\"ChannelName\"])\n",
    "    if channel_name == \"Unknown\":\n",
    "        video_id = str(row[\"VideoID\"])\n",
    "        if req_count > 9000:\n",
    "            NUM+=1\n",
    "            req_count=0\n",
    "        req_count+=1\n",
    "\n",
    "        result_ids.append(getChannelName.remote(idx, video_id, KEYS[idx%len(KEYS)]))\n",
    "\n",
    "\n",
    "while len(result_ids):\n",
    "    done_id, result_ids = ray.wait(result_ids)\n",
    "    test=ray.get(done_id)\n",
    "#     print(test)\n",
    "# out: [(31, 'Unknown')]\n",
    "\n",
    "    idx, channel_name = test[0]\n",
    "    yt_df.loc[idx,'ChannelName'] = channel_name\n",
    "\n",
    "yt_df.to_csv(baseloc+'/youtube.csv',index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yt_df.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"total number of post: {idf['번호'].count()}\")\n",
    "print(idf.sort_values(by=['추천 수'], ascending=False).head(n=1))\n",
    "print(\"\\n\")\n",
    "print(idf.sort_values(by=['조회 수'], ascending=False).head(n=1))\n",
    "print(\"\\n\")\n",
    "print(idf.sort_values(by=['달린 댓글 수'], ascending=False).head(n=1))\n",
    "print(\"\\n\")\n",
    "print(idf[\"개념글 수\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nr0Vc84r6Zdx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
