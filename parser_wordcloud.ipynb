{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Web scrapper"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from datetime import datetime\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "os.environ['CLASSPATH'] = \"./KotlinInside-1.10.2-all.jar\"\r\n",
    "\r\n",
    "from jnius import autoclass\r\n",
    "\r\n",
    "gall = 'kizunaai' #갤러리 id\r\n",
    "start_year=datetime.now().year\r\n",
    "end_year=datetime.now().year\r\n",
    "\r\n",
    "user=autoclass(\"be.zvz.kotlininside.session.user.Anonymous\")\r\n",
    "inside=autoclass(\"be.zvz.kotlininside.KotlinInside\")\r\n",
    "http=autoclass(\"be.zvz.kotlininside.http.DefaultHttpClient\")\r\n",
    "\r\n",
    "test=inside.createInstance(user(\"ㅇㅇ\",\"zhxmfflsakstp\"), http(True,True))\r\n",
    "test=inside(user(\"ㅇㅇ\",\"zhxmfflsakstp\"), http(True,True), True)\r\n",
    "test.generateClientToken()\r\n",
    "# db 디렉토리를 생성, 초기화\r\n",
    "# for year in range(start_year,end_year+1): #2018~2019년 폴더 생성\r\n",
    "\r\n",
    "#     for month in range(1,12+1): #1~12월 폴더 생성\r\n",
    "#         baseloc = os.path.abspath('./%s/%s/%s/' % (gall,year,month)) # 경로\r\n",
    "        \r\n",
    "#         if not os.path.exists(baseloc+'table'): os.makedirs(baseloc+'table')\r\n",
    "#         if not os.path.exists(baseloc+'word'):os.makedirs(baseloc+'word') #table, word 폴더는 다른 통계 코드용\r\n",
    "#         pd.DataFrame(columns=['번호','제목','날짜','닉네임','ID/IP','조회 수','달린 댓글 수','추천 수','비추 수','content','mobile','개념글 수','idtype']).to_json(baseloc+'post.json')\r\n",
    "#         pd.DataFrame(columns=['번호','날짜','닉네임','ID/IP','dccon','content','idtype','답글 대상','댓삭 당한 횟수']).to_json(baseloc+'comment.json')\r\n",
    "# RDQ1L1NtWGFWR3RDenZuNzhBMlBBbWJNbzllYmgwaVZZNFB6djNJUlFGWT0=\r\n",
    "# RDQ1L1NtWGFWR3RDenZuNzhBMlBBZy9DQnpmUG9BR0pTTnNINnk4ekVrMD0="
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'UFUzUnI4N1NKOVdTd3gyeVU3UzBQRDQ4RmVRTWhhNzBKV3gvRXh5OUExTT0='"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(test.generateAppId())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "UFUzUnI4N1NKOVdTd3gyeVU3UzBQQjBVZkZzcEZqMTlzNjkxNXNSOHd2TT0=\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import gevent.monkey\r\n",
    "gevent.monkey.patch_socket()\r\n",
    "gevent.monkey.patch_ssl()\r\n",
    "import re,requests,sys,time,html,random\r\n",
    "from gevent.pool import Pool\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import string\r\n",
    "import html\r\n",
    "from base64 import b64encode\r\n",
    "from hashlib import sha256\r\n",
    "\r\n",
    "session = requests.Session()\r\n",
    "app_id=0\r\n",
    "\r\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\r\n",
    "    return ''.join(random.choice(chars) for _ in range(size))\r\n",
    "\r\n",
    "def get_app_id(): #공앱에서 사용하는 app_id 값 받아오기. 주기적으로 새로 발급해야함\r\n",
    "    app_id = test.generateAppId()\r\n",
    "    return app_id\r\n",
    "\r\n",
    "def gethtml(no): #글 수집\r\n",
    "    count = 0 #에러 체크용 카운트, 10 넘으면 스크랩 패스\r\n",
    "    url = \"http://m.dcinside.com/api/gall_view_new.php?id=\"+gall+\"&no=\"+str(no)+\"&app_id=\"+app_id\r\n",
    "    while True:\r\n",
    "        try:\r\n",
    "            a = session.get('http://m.dcinside.com/api/redirect.php?hash='+b64encode(url.encode('utf-8')).decode('utf-8'),headers={\"User-Agent\": \"dcinside.app\"},timeout=5)\r\n",
    "            if r'\\uae00\\uc5c6\\uc74c' in a.text: return; # 삭제된 글 체크\r\n",
    "            intro = a.json(strict=False)[0]['view_info'];view = a.json(strict=False)[0]['view_main']\r\n",
    "            postcontent = view['memo'] #글 내용\r\n",
    "            postIP = intro['user_id'] if len(intro['ip'])==0 else intro['ip'] #작성자 IP\r\n",
    "            mobile = False if intro['write_type']=='W' else True #모바일 체크\r\n",
    "            recom = False if intro['recommend_chk'] == 'N' else True #개념글 체크\r\n",
    "            break\r\n",
    "        except requests.exceptions.RequestException as e:pass\r\n",
    "        except requests.Timeout as e:pass\r\n",
    "        except Exception as e:\r\n",
    "            if not('<!DOCTYPE html>' in a.text or a.text == ''):print(no,'idf', end=' ');print(str(e));print(a.text)\r\n",
    "            count+=1\r\n",
    "            if count > 10:sys.exit()\r\n",
    "    \r\n",
    "    #댓글\r\n",
    "    replypage = 1;total_comment = 0;passnick = 'deleted';passIP = 'deleted'\r\n",
    "    while True:\r\n",
    "        mobileurl = \"http://m.dcinside.com/api/redirect.php?hash=\"+b64encode((\"http://m.dcinside.com/api/comment_new.php?csort=new&id=\"+gall+\"&no=\"+str(no)+\"&re_page=\"+str(replypage)+\"&app_id=\"+app_id+\"=\").encode('utf-8')).decode('utf-8')+\"%3D%3D\"\r\n",
    "        count=0 #에러 체크용 카운트, 10 넘으면 스크랩 패스\r\n",
    "        while True:\r\n",
    "            try:\r\n",
    "                a = session.get(mobileurl,headers={\"User-Agent\": \"dcinside.app\"},timeout=5)\r\n",
    "                comment = a.json(strict=False)[0]\r\n",
    "                for comm in comment['comment_list']:\r\n",
    "                    if not('ipData' in comm.keys()): comm['ipData'] = ''\r\n",
    "                    if 'under_step' in comm.keys(): target = '%s (%s)' % (passnick,passIP);\r\n",
    "                    else: passnick = comm['name']; passIP = comm['user_id'] if len(comm['ipData'])==0 else comm['ipData']; target = None\r\n",
    "                    IP = comm['user_id'] if len(comm['ipData'])==0 else comm['ipData']\r\n",
    "                    dccon = True if 'dccon' in comm.keys() else False\r\n",
    "                    if 'is_delete_flag' in comm.keys():\r\n",
    "                        if '작성자' in comm['is_delete_flag']: removed_by_writer = True\r\n",
    "                        else: removed_by_writer = False\r\n",
    "                    else: removed_by_writer = False\r\n",
    "                    content = comm['comment_memo'] if dccon==False else comm['dccon']\r\n",
    "                    commlist.append({u'번호':no,u'날짜':comm['date_time'],u'닉네임':comm['name'],'ID/IP':IP,'idtype':comm['member_icon'],'content':content, 'dccon':dccon,\r\n",
    "                                     '답글 대상':target, '댓삭 당한 횟수':removed_by_writer})\r\n",
    "                break\r\n",
    "            except requests.exceptions.RequestException as e:pass\r\n",
    "            except requests.Timeout as e:pass\r\n",
    "            except Exception as e:\r\n",
    "                if not('<!DOCTYPE html>' in a.text or a.text == ''): print(no,'cdf', end=' ');print(str(e)); print(a.text)\r\n",
    "                count+=1\r\n",
    "                if count > 5:sys.exit()\r\n",
    "\r\n",
    "        if len(comment['comment_list']) == 0: break\r\n",
    "        else: total_comment+= len(comment['comment_list'])\r\n",
    "        replypage+=1\r\n",
    "    postlist.append({u'번호':no,u'제목':intro['subject'],u'날짜':intro['date_time'],u'닉네임':intro['name'],'ID/IP':postIP,'idtype':intro['member_icon'],\r\n",
    "                     u'조회 수':intro['hit'],u'달린 댓글 수':total_comment,u'추천 수':view['recommend'],u'비추 수':view['nonrecommend'],\r\n",
    "                     'content':postcontent,'mobile':mobile,u'개념글 수':recom})\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import datetime\r\n",
    "start = 2499139 #시작 번호 (젤 최근 게시글 번호)\r\n",
    "end = 2185219 # 종료 번호\r\n",
    "gall = 'kizunaai';year=datetime.now().year; month =datetime.now().month-1 # 갤러리, 연, 월\r\n",
    "baseloc = os.path.abspath('./%s/%s/%s/' % (gall,year,month)) # 경로\r\n",
    "turn = 400 # step 한국어로 뭐라하는지 모름\r\n",
    "\r\n",
    "pool = Pool()\r\n",
    "print(\"Ready\")\r\n",
    "idf = pd.read_json(baseloc+'post.json');cdf = pd.read_json(baseloc+'comment.json')\r\n",
    "app_id=get_app_id()\r\n",
    "exit=False\r\n",
    "total_val = (start-end+1)//turn+1\r\n",
    "with tqdm(total=total_val) as pbar: # 소요 시간 출력\r\n",
    "    while True:\r\n",
    "        start_time = time.perf_counter() # 시간 측정용 현재 시간 저장\r\n",
    "        commlist = [];postlist = [] # dataframe 변환용 list 초기화\r\n",
    "        pl = list(range(start+1-turn,start+1)); pl.reverse()\r\n",
    "#         postlist = idf[u'번호'].values.tolist() # 중복 글 체크용 번호 목록 생성\r\n",
    "        for postnum in pl:\r\n",
    "            if postnum < end: \r\n",
    "                exit = True\r\n",
    "                break # 종료 번호보다 오래된 글 일시 패스\r\n",
    "#             if postnum in postlist: \r\n",
    "#                 continue # 중복 글 체크용인데 보통은 안 쓰니 주석처리 해놓는게 처리속도 더 빠름\r\n",
    "            pool.spawn(gethtml,postnum)\r\n",
    "        pool.join()\r\n",
    "        print(len(postlist), end = \" |\") # 수집 글 갯수\r\n",
    "        pbar.update(1) # 소요 시간 업데이트\r\n",
    "        start = start - turn\r\n",
    "        if len(postlist) != 0: pd.concat([idf, pd.DataFrame(postlist)],sort=False).reset_index(drop=True).to_json(baseloc+'post.json')\r\n",
    "        if len(commlist) != 0: pd.concat([cdf, pd.DataFrame(commlist)],sort=False).reset_index(drop=True).to_json(baseloc+'comment.json') #저장\r\n",
    "        if exit==True: break\r\n",
    "        if len(postlist) != 0: app_id=get_app_id();idf = pd.read_json(baseloc+'post.json');cdf = pd.read_json(baseloc+'comment.json') # db에 추가된 거 있을시 다시 로드\r\n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ready\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc838994c8f4b05a6903f070ccceedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "395 |392 |389 |389 |385 |388 |381 |379 |387 |380 |382 |365 |378 |383 |384 |386 |395 |384 |370 |355 |362 |373 |379 |386 |387 |385 |394 |391 |398 |383 |385 |387 |387 |378 |376 |377 |383 |386 |393 |376 |361 |352 |377 |379 |390 |389 |383 |383 |381 |385 |380 |382 |383 |373 |383 |380 |380 |380 |372 |386 |378 |366 |381 |367 |393 |392 |395 |387 |390 |372 |386 |373 |375 |392 |390 |380 |385 |378 |395 |365 |380 |388 |381 |376 |388 |372 |382 |373 |386 |382 |386 |388 |380 |392 |376 |381 |365 |384 |364 |383 |383 |391 |393 |387 |389 |388 |388 |388 |387 |382 |382 |386 |390 |385 |385 |384 |384 |381 |386 |381 |372 |369 |363 |374 |359 |383 |383 |383 |380 |376 |358 |371 |371 |361 |382 |383 |384 |380 |379 |384 |375 |380 |386 |382 |386 |382 |367 |356 |359 |376 |377 |377 |379 |351 |386 |374 |388 |386 |373 |378 |377 |380 |382 |365 |370 |365 |347 |367 |386 |395 |383 |383 |389 |381 |364 |370 |374 |384 |374 |373 |369 |367 |389 |382 |382 |380 |380 |375 |387 |370 |373 |380 |389 |381 |380 |372 |375 |377 |373 |374 |380 |372 |361 |351 |378 |375 |380 |376 |378 |387 |381 |384 |387 |388 |390 |364 |360 |382 |385 |385 |385 |386 |383 |390 |389 |391 |389 |386 |390 |382 |382 |386 |379 |360 |370 |372 |369 |379 |366 |375 |386 |382 |379 |384 |379 |381 |376 |373 |382 |376 |379 |380 |383 |382 |365 |383 |370 |378 |379 |362 |374 |375 |368 |370 |382 |380 |380 |366 |379 |382 |375 |382 |370 |377 |374 |380 |385 |389 |383 |385 |381 |378 |385 |385 |383 |378 |373 |379 |391 |383 |385 |377 |383 |386 |386 |384 |382 |386 |389 |385 |380 |362 |364 |381 |369 |359 |367 |384 |378 |388 |376 |369 |365 |371 |365 |382 |382 |387 |386 |377 |376 |380 |376 |376 |377 |373 |370 |365 |360 |356 |366 |385 |384 |392 |383 |381 |379 |390 |385 |393 |380 |382 |368 |360 |369 |360 |369 |384 |374 |361 |360 |362 |378 |375 |387 |382 |384 |389 |379 |380 |377 |380 |384 |382 |371 |368 |356 |377 |372 |376 |361 |361 |356 |367 |349 |363 |366 |373 |358 |370 |367 |379 |374 |379 |377 |390 |389 |387 |375 |378 |362 |371 |371 |372 |365 |374 |372 |381 |374 |373 |380 |377 |378 |378 |379 |382 |380 |385 |388 |385 |373 |378 |388 |369 |368 |366 |374 |371 |374 |379 |381 |379 |386 |372 |376 |373 |350 |379 |380 |359 |365 |366 |362 |378 |371 |372 |371 |376 |383 |390 |381 |377 |354 |375 |360 |383 |377 |363 |347 |356 |371 |377 |386 |375 |385 |381 |384 |388 |394 |392 |381 |393 |"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 중복글 제거\r\n",
    "# idf = pd.read_json(baseloc+'post.json');\r\n",
    "# cdf = pd.read_json(baseloc+'comment.json') # db에 추가된 거 있을시 다시 로드\r\n",
    "\r\n",
    "# idf.drop_duplicates(['번호']).to_json(baseloc+'post.json')\r\n",
    "# cdf.drop_duplicates(['번호']).to_json(baseloc+'comment.json') #저장\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# html 제거\r\n",
    "idf = pd.read_json(baseloc+'post.json');\r\n",
    "cdf = pd.read_json(baseloc+'comment.json') # db에 추가된 거 있을시 다시 로드\r\n",
    "\r\n",
    "# cdf.drop_duplicates(['번호']).to_json(baseloc+'comment.json') #저장\r\n",
    "idf[\"content\"]=idf[\"content\"].str.replace(r'<[^<]+?>','',regex=True)\r\n",
    "idf.to_json(baseloc+'post.json')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# tagging"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from PyKomoran import *\r\n",
    "\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from collections import Counter, defaultdict\r\n",
    "from datetime import datetime, timedelta\r\n",
    "from PIL import Image\r\n",
    "from wordcloud import WordCloud, ImageColorGenerator\r\n",
    "import jpype,time,json,sys,calendar,json,collections\r\n",
    "from datetime import datetime\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "import vtuber_dict as vd\r\n",
    "\r\n",
    "vtuber_dict=vd.vtuber\r\n",
    "nicknames = vd.nicknames\r\n",
    "dict_file = '/mnt/e/helloworld/user_dict.txt'\r\n",
    "userdict_df=pd.read_csv(dict_file, names=[\"단어\"], index_col=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 자동 사전 단어 추가\r\n",
    "for vtuber, nicknames in tqdm(vtuber_dict.items()):\r\n",
    "    for nickname in nicknames:\r\n",
    "        if not userdict_df[\"단어\"].isin([nickname]).any():\r\n",
    "            to_append = [nickname]\r\n",
    "            userdict_df.loc[len(userdict_df)] = to_append\r\n",
    "userdict_df.to_csv(dict_file, header=False, index=False)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1bdaa5370d4420991deccf5e90407e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "gall = 'kizunaai';year=datetime.now().year; month =datetime.now().month-1 # 갤러리, 연, 월\r\n",
    "baseloc = os.path.abspath('./%s/%s/%s/' % (gall,year,month)) # 경로\r\n",
    "\r\n",
    "one_word_filter = userdict_df['단어'][userdict_df['단어'].str.len() == 1].tolist()\r\n",
    "count_tags=defaultdict(int)\r\n",
    "\r\n",
    "def get_kodict():\r\n",
    "    ko=Komoran(\"STABLE\")\r\n",
    "    ko.set_user_dic(dict_file)\r\n",
    "    return ko\r\n",
    "\r\n",
    "try:\r\n",
    "    jpype.startJVM()\r\n",
    "except:\r\n",
    "    pass\r\n",
    "\r\n",
    "k = get_kodict()\r\n",
    "arr_filter=[]\r\n",
    "\r\n",
    "\r\n",
    "def tagging(tags, count_tags, a):\r\n",
    "    try:\r\n",
    "        jpype.java.lang.Thread.attach()\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "    \r\n",
    "#         if len(a) > 1000:continue\r\n",
    "    if not arr_filter and any(word in a for word in arr_filter):\r\n",
    "        return list()\r\n",
    "    try:\r\n",
    "        nouns = k.nouns(\"\\n\".join([s for s in a.split(\"\\n\") if s]));nouns = list(set(nouns)); count = Counter(nouns)\r\n",
    "    except:\r\n",
    "        return\r\n",
    "\r\n",
    "    count_list = list(count)\r\n",
    "    for word in count_list:\r\n",
    "        if not word in one_word_filter and len(word) == 1:\r\n",
    "            del count[word]\r\n",
    "            \r\n",
    "    for n in list(count.elements()):\r\n",
    "#         if not n in tags.keys():\r\n",
    "#             tags[n]=1\r\n",
    "#         else:\r\n",
    "        tags[n]+=1\r\n",
    "          \r\n",
    "        if n in nicknames:\r\n",
    "            for vtuber, calls in vtuber_dict.items():\r\n",
    "                if n in calls:\r\n",
    "#                     if not vtuber in count_tags.keys():\r\n",
    "#                         count_tags[vtuber]=1\r\n",
    "#                     else:\r\n",
    "                    count_tags[vtuber]+=1\r\n",
    "                    break\r\n",
    "    return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "idf = pd.read_json(baseloc+'post.json');cdf = pd.read_json(baseloc+'comment.json')\r\n",
    "cdf=cdf[cdf['dccon']==False]\r\n",
    "cont = pd.concat([idf, cdf],sort=False)\r\n",
    "cont[u'날짜'] = pd.to_datetime(cont[u'날짜'],format='%Y.%m.%d')\r\n",
    "cont[\"content\"]=cont[\"content\"].str.replace(r'<[^<]+?>','',regex=True)\r\n",
    "first = str(year)+'-'+str(month)\r\n",
    "last = str(year)+'-'+str(month+1) if month != 12 else str(year+1)+'-1'\r\n",
    "\r\n",
    "\r\n",
    "for beg in tqdm(pd.date_range(first, last,closed='left', freq='D'), position=0):\r\n",
    "    acont = cont[(cont[u'날짜'] >= beg + timedelta(hours=6)) & (cont[u'날짜'] < beg + timedelta(hours=30))]\r\n",
    "    start_time = time.time()\r\n",
    "    print (beg.month,beg.day,end=' '),\r\n",
    "    econt = acont[(acont[u'날짜'] >= beg + timedelta(hours=6)) & (acont[u'날짜'] < beg + timedelta(hours=18))]\r\n",
    "    alines = econt[u'제목']+'\\n'+econt['content']\r\n",
    "    alines = alines.dropna().tolist()\r\n",
    "    lines =alines\r\n",
    "    tags = defaultdict(int) \r\n",
    "    print('Number of lines in document:',end=' '),\r\n",
    "    nlines = len(lines)\r\n",
    "    print (nlines,end=' ')\r\n",
    "    for line in lines:\r\n",
    "        a = str(line)\r\n",
    "        tagging(tags, count_tags, a)\r\n",
    "#     t1 = Process(target=do_concurrent_tagging, args=(0, int(nlines/2), lines))\r\n",
    "#     t2 = Process(target=do_concurrent_tagging, args=(int(nlines/2), nlines, lines))\r\n",
    "#     t1.start(); t2.start(); t1.join(); t2.join()\r\n",
    "    print(\"%.2f\" % (time.time() - start_time) +u'초',end=' ')\r\n",
    "    os.remove(baseloc+'word/'+str(beg.day)+'_day.json')\r\n",
    "    with open(baseloc+'word/'+str(beg.day)+'_day.json', 'w') as f:\r\n",
    "        json.dump(tags.copy(), f)\r\n",
    "\r\n",
    "    start_time = time.time()\r\n",
    "    tags = defaultdict(int)\r\n",
    "    econt = acont[(acont[u'날짜'] < beg + timedelta(hours=30)) & (acont[u'날짜'] >= beg + timedelta(hours=18))]\r\n",
    "    alines = econt[u'제목']+'\\n'+econt['content']\r\n",
    "    alines = alines.dropna().tolist()\r\n",
    "    lines =alines\r\n",
    "    \r\n",
    "    print('Number of lines in document:',end=' '),\r\n",
    "    nlines = len(lines)\r\n",
    "    print (nlines,end=' ')\r\n",
    "#     with Pool(3) as p:\r\n",
    "    for line in lines:\r\n",
    "        a = str(line)\r\n",
    "        tagging(tags, count_tags, a)\r\n",
    "#     t1 = Process(target=do_concurrent_tagging, args=(0, int(nlines/2), lines))\r\n",
    "#     t2 = Process(target=do_concurrent_tagging, args=(int(nlines/2), nlines, lines))\r\n",
    "#     t1.start(); t2.start();t1.join(); t2.join()\r\n",
    "    print(\"%.2f\" % (time.time() - start_time) +u'초')\r\n",
    "    #print ' '.join(tags)\r\n",
    "    os.remove(baseloc+'word/'+str(beg.day)+'_night.json')\r\n",
    "    with open(baseloc+'word/'+str(beg.day)+'_night.json', 'w') as f:\r\n",
    "        json.dump(tags.copy(), f)\r\n",
    "\r\n",
    "totaltag = []\r\n",
    "lastday = calendar.monthrange(year,month)[1]\r\n",
    "for beg in range(1,lastday+1):\r\n",
    "    with open(baseloc+'word/'+str(beg)+'_day.json', 'r') as f:totaltag.append(dict(json.load(f)))\r\n",
    "    with open(baseloc+'word/'+str(beg)+'_night.json', 'r') as f:totaltag.append(dict(json.load(f)))\r\n",
    "counter = collections.Counter()\r\n",
    "for d in totaltag:counter.update(d)\r\n",
    "tagsdict = dict(counter)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5494d96c06473eb922c0ab0a6b866c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8 1 Number of lines in document: 3237 8.26초 Number of lines in document: 8038 20.25초\n",
      "8 2 Number of lines in document: 2022 5.87초 Number of lines in document: 3763 8.33초\n",
      "8 3 Number of lines in document: 2207 6.21초 Number of lines in document: 4181 10.41초\n",
      "8 4 Number of lines in document: 1825 4.40초 Number of lines in document: 3490 7.57초\n",
      "8 5 Number of lines in document: 2046 4.93초 Number of lines in document: 4012 8.73초\n",
      "8 6 Number of lines in document: 1743 4.20초 Number of lines in document: 4347 9.46초\n",
      "8 7 Number of lines in document: 2481 5.27초 Number of lines in document: 5469 12.10초\n",
      "8 8 Number of lines in document: 2586 5.68초 Number of lines in document: 7432 15.38초\n",
      "8 9 Number of lines in document: 2719 6.12초 Number of lines in document: 5698 12.80초\n",
      "8 10 Number of lines in document: 2344 5.73초 Number of lines in document: 5852 13.65초\n",
      "8 11 Number of lines in document: 1948 4.57초 Number of lines in document: 7072 14.12초\n",
      "8 12 Number of lines in document: 2190 5.02초 Number of lines in document: 4882 10.46초\n",
      "8 13 Number of lines in document: 5612 11.03초 Number of lines in document: 5366 13.99초\n",
      "8 14 Number of lines in document: 5059 11.72초 Number of lines in document: 5453 12.42초\n",
      "8 15 Number of lines in document: 2465 6.31초 Number of lines in document: 9316 20.01초\n",
      "8 16 Number of lines in document: 1742 3.93초 Number of lines in document: 6469 15.14초\n",
      "8 17 Number of lines in document: 4735 11.45초 Number of lines in document: 6467 16.21초\n",
      "8 18 Number of lines in document: 2591 7.40초 Number of lines in document: 6547 14.57초\n",
      "8 19 Number of lines in document: 2397 5.18초 Number of lines in document: 5437 11.11초\n",
      "8 20 Number of lines in document: 2627 5.76초 Number of lines in document: 6038 14.39초\n",
      "8 21 Number of lines in document: 2417 5.82초 Number of lines in document: 6194 15.12초\n",
      "8 22 Number of lines in document: 2381 5.78초 Number of lines in document: 14713 31.78초\n",
      "8 23 Number of lines in document: 10227 23.43초 Number of lines in document: 7673 17.85초\n",
      "8 24 Number of lines in document: 3704 9.10초 Number of lines in document: 5472 13.42초\n",
      "8 25 Number of lines in document: 5252 12.25초 Number of lines in document: 6568 15.70초\n",
      "8 26 Number of lines in document: 3759 9.01초 Number of lines in document: 6233 14.74초\n",
      "8 27 Number of lines in document: 3748 9.46초 Number of lines in document: 9574 20.78초\n",
      "8 28 Number of lines in document: 3726 8.33초 Number of lines in document: 5733 12.09초\n",
      "8 29 Number of lines in document: 4250 8.87초 Number of lines in document: 7373 17.26초\n",
      "8 30 Number of lines in document: 2737 7.23초 Number of lines in document: 5534 13.54초\n",
      "8 31 Number of lines in document: 3230 7.48초 Number of lines in document: 3870 9.31초\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Wordcloud"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "os.makedirs(baseloc, exist_ok=True)\r\n",
    "cur_dir='./'\r\n",
    "r=[\"!!!\",\".com\",\".kr\",\".co\",\".be\",\"오늘\",\"진짜\",\"이거\",\"사람\",\"시간\",\"생각\",\"시작\",\"하나\",\"해서\",\"이상\",\"들이\",\"하면\",\"얘기\",\"하게\",\"하네\",\"어제\",\"뭔가\",\"안보\",\"그거\",\"고싶\",\"그새\",\"이번\"]\r\n",
    "for k in r:tagsdict.pop(k, None)\r\n",
    "maskfile = np.array(Image.open(os.path.abspath(f\"{cur_dir}/ai.jpg\")))\r\n",
    "wc = WordCloud(font_path=r'/mnt/c/Windows/Fonts/BMDOHYEON_ttf.ttf',\r\n",
    "               mode = \"RGBA\", background_color=None,\r\n",
    "               max_words=1000,\r\n",
    "               mask=maskfile,\r\n",
    "               prefer_horizontal=1,\r\n",
    "               min_font_size=0,\r\n",
    "               max_font_size=150,\r\n",
    "               width=1398.425197, height=2116.535433, scale=5\r\n",
    "                ).generate_from_frequencies(tagsdict)\r\n",
    "image_colors = ImageColorGenerator(maskfile)\r\n",
    "wc.recolor(color_func=image_colors, random_state=0).to_file(f\"{baseloc}/wordcloud.png\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7f9777cc2cd0>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from parsers import parser\r\n",
    "import vtuber_dict as vd\r\n",
    "import os\r\n",
    "from datetime import datetime\r\n",
    "gall = 'kizunaai';year=datetime.now().year; month =datetime.now().month-1 # 갤러리, 연, 월\r\n",
    "baseloc = os.path.abspath('./%s/%s/%s/' % (gall,year,month)) # 경로\r\n",
    "\r\n",
    "parser(baseloc, vd.nijisanji, 'sum_niji.csv')\r\n",
    "parser(baseloc, vd.hololive, 'sum_holo.csv')\r\n",
    "parser(baseloc, vd.vtuber, 'sum_ai.csv')\r\n",
    "parser(baseloc, vd.exceptholo, 'sum_noholo.csv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2번째 바 길이: 16.892876427829695\n",
      "3번째 바 길이: 13.057528556593976\n",
      "4번째 바 길이: 9.742554517133955\n",
      "5번째 바 길이: 9.520913811007267\n",
      "6번째 바 길이: 8.827082035306333\n",
      "7번째 바 길이: 7.323779854620975\n",
      "8번째 바 길이: 6.919044652128763\n",
      "9번째 바 길이: 5.666292834890965\n",
      "10번째 바 길이: 5.425379023883696\n",
      "Top10에서 사라진:      Vtuber                                           단어(언급 수)  총 언급 횟수\n",
      "14   셀렌 타츠키                                     셀렌(491)+타츠키(1)      492\n",
      "16   군도 미레이  군도(343)+미레이(85)+도 미레이(43)+미래이(2)+미.레이(0)+미1레이(...      473\n",
      "17   마치타 치마                                            치마(472)      472\n",
      "24  유우키 치히로          치히로(185)+치재앙(157)+마법소녀(28)+치여사(13)+치쨩(12)      395\n",
      "2번째 바 길이: 10.775435083608478\n",
      "3번째 바 길이: 8.761094898285227\n",
      "4번째 바 길이: 8.729466396847375\n",
      "5번째 바 길이: 7.571072531686015\n",
      "6번째 바 길이: 7.377347960379167\n",
      "7번째 바 길이: 6.837686654595803\n",
      "8번째 바 길이: 6.596519331132176\n",
      "9번째 바 길이: 6.37314303972734\n",
      "10번째 바 길이: 6.337560975609756\n",
      "Top10에서 사라진:       Vtuber                                           단어(언급 수)  총 언급 횟수\n",
      "11   아마네 카나타  가짜(1451)+가짜가짜(744)+카나타(718)+가짜천사(90)+카나땅(45)+텐...     3138\n",
      "13  츠노마키 와타메  양이모(1612)+와타메(999)+츠노마키(56)+도도도(51)+콘방도도도(14)+...     2747\n",
      "14   토코야미 토와  톼삼(1852)+토와(754)+군와(44)+토와사마(43)+나루미(31)+카나토와(...     2739\n",
      "17  나츠이로 마츠리           라팡(1624)+마츠리(786)+고토(44)+노조미(40)+라도팡주(4)     2498\n",
      "25   우루하 루시아            루굴(942)+루시아(698)+미케네코(35)+마리루시(3)+캠굴(0)     1678\n",
      "2번째 바 길이: 10.775435083608478\n",
      "3번째 바 길이: 8.761094898285227\n",
      "4번째 바 길이: 8.729466396847375\n",
      "5번째 바 길이: 7.571072531686015\n",
      "6번째 바 길이: 7.377347960379167\n",
      "7번째 바 길이: 6.837686654595803\n",
      "8번째 바 길이: 6.596519331132176\n",
      "9번째 바 길이: 6.37314303972734\n",
      "10번째 바 길이: 6.337560975609756\n",
      "Top10에서 사라진:       Vtuber                                           단어(언급 수)  총 언급 횟수\n",
      "11   아마네 카나타  가짜(1451)+가짜가짜(744)+카나타(718)+가짜천사(90)+카나땅(45)+텐...     3138\n",
      "13  츠노마키 와타메  양이모(1612)+와타메(999)+츠노마키(56)+도도도(51)+콘방도도도(14)+...     2747\n",
      "14   토코야미 토와  톼삼(1852)+토와(754)+군와(44)+토와사마(43)+나루미(31)+카나토와(...     2739\n",
      "17  나츠이로 마츠리           라팡(1624)+마츠리(786)+고토(44)+노조미(40)+라도팡주(4)     2498\n",
      "66   아토리 코토코      갈꼬(424)+코토코(15)+kotoko(12)+Atori(0)+KOTOKO(0)      451\n",
      "2번째 바 길이: 18.184174454828657\n",
      "3번째 바 길이: 16.892876427829695\n",
      "4번째 바 길이: 15.052294911734162\n",
      "5번째 바 길이: 13.057528556593976\n",
      "6번째 바 길이: 9.742554517133955\n",
      "7번째 바 길이: 9.520913811007267\n",
      "8번째 바 길이: 9.106542056074765\n",
      "9번째 바 길이: 8.855991692627205\n",
      "10번째 바 길이: 8.827082035306333\n",
      "Top10에서 사라진:       Vtuber                                       단어(언급 수)  총 언급 횟수\n",
      "11    츠키노 미토                  천황(432)+미토(296)+위원장(32)+욘토(0)      760\n",
      "12    카이다 하루                                        하루(718)      718\n",
      "14  니시조노 치구사                       치구사(561)+해바라기(20)+히이로(7)      588\n",
      "24   아토리 코토코  갈꼬(424)+코토코(15)+kotoko(12)+Atori(0)+KOTOKO(0)      451\n",
      "32   유우키 치히로      치히로(185)+치재앙(157)+마법소녀(28)+치여사(13)+치쨩(12)      395\n",
      "35       피카미                         피카미(370)+끠카미(7)+끠까미(5)      382\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import vtuber_dict as vd\r\n",
    "import word_dict as wd\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "from datetime import datetime\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# df[df['col'].str.contains(\"hello|train\",na=False)]\r\n",
    "\r\n",
    "first = str(year)+'-'+str(month)\r\n",
    "last = str(year)+'-'+str(month+1) if month != 12 else str(year+1)+'-1'\r\n",
    "vtuber_dict=vd.vtuber\r\n",
    "word_dict=wd.word_dict\r\n",
    "total_col=['Vtuber','관련 글/댓글 수']\r\n",
    "\r\n",
    "for award in word_dict:\r\n",
    "    total_col.append(award)\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "try:\r\n",
    "    cont[\"제목내용\"]=cont[u'제목'].astype(str)+'\\n'+cont['content'].astype(str)\r\n",
    "except NameError as e:\r\n",
    "    idf = pd.read_json(baseloc+'post.json');cdf = pd.read_json(baseloc+'comment.json')\r\n",
    "    cdf=cdf[cdf['dccon']==False]\r\n",
    "    cont = pd.concat([idf, cdf],sort=False)\r\n",
    "    cont[\"제목내용\"]=cont[u'제목'].astype(str)+'\\n'+cont['content'].astype(str)\r\n",
    "    \r\n",
    "cont[\"제목내용\"]=cont[\"제목내용\"].str.replace(r'<[^<]+?>','',regex=True)\r\n",
    "total_info=[]\r\n",
    "total_percent_info=[]\r\n",
    "\r\n",
    "reader_path=baseloc+'/sum_ai.csv'\r\n",
    "df = pd.read_csv(reader_path, index_col=0)\r\n",
    "target_vtuber=df[\"Vtuber\"].values\r\n",
    "count_tags_keys = count_tags.keys()\r\n",
    "for vtuber in tqdm(target_vtuber):\r\n",
    "    award_col=[vtuber]\r\n",
    "    award_percent_col=[vtuber]\r\n",
    "    fillters=''\r\n",
    "    \r\n",
    "    for nickname in vtuber_dict[vtuber]:\r\n",
    "        fillters+= nickname+'|'\r\n",
    "    fillters=fillters[:-1]\r\n",
    "#     print(fillters)\r\n",
    "    vdtuer_df=cont[cont['제목내용'].str.contains(fillters,na=False, regex = True)][['제목내용']]\r\n",
    "#     print(vdtuer_df['제목내용'])\r\n",
    "    \r\n",
    "    vtuber_count = count_tags[vtuber] if vtuber in count_tags_keys else 0\r\n",
    "    award_col.append(vtuber_count)\r\n",
    "    award_percent_col.append(vtuber_count)\r\n",
    "    for award in word_dict:\r\n",
    "        award_fillters=''\r\n",
    "        for word in word_dict[award]:\r\n",
    "            award_fillters+= word+'|'\r\n",
    "        award_fillters=award_fillters[:-1]\r\n",
    "#         print(award_fillters)\r\n",
    "        award_df=vdtuer_df[vdtuer_df['제목내용'].str.contains(award_fillters,na=False, regex = True)]\r\n",
    "        award_count=len(award_df)\r\n",
    "#         print(award_df['제목내용'])\r\n",
    "        if award_count == 0 or vtuber_count == 0:\r\n",
    "            award_percent_col.append(0)\r\n",
    "        else:\r\n",
    "            award_percent_col.append(award_count/vtuber_count*100)\r\n",
    "        award_col.append(award_df['제목내용'].count())\r\n",
    "#     print(award_fillters)\r\n",
    "    \r\n",
    "    total_info.append(award_col)\r\n",
    "    total_percent_info.append(award_percent_col)\r\n",
    "#     break\r\n",
    "    \r\n",
    "total_per_df = pd.DataFrame(total_percent_info, columns=total_col)\r\n",
    "total_per_df.to_csv(baseloc+'/award_percent.csv', sep=',', index=True)\r\n",
    "\r\n",
    "total_df = pd.DataFrame(total_info, columns=total_col)\r\n",
    "total_df.to_csv(baseloc+'/award.csv', sep=',', index=True)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9015395540b1448ba09dd6e250a2cc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from datetime import datetime\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "import os \r\n",
    "\r\n",
    "old_month = month - 1\r\n",
    "old_year = year\r\n",
    "if month is 1:\r\n",
    "    old_month = 12\r\n",
    "    old_year = year - 1\r\n",
    "oldloc=os.path.abspath('./%s/%s/%s/' % (gall,old_year,old_month))\r\n",
    "\r\n",
    "\r\n",
    "# pd.read_csv(baseloc+\"/award.csv\")\r\n",
    "# for award in word_dict:\r\n",
    "#     print(f\"{award} Award\")\r\n",
    "#     print(total_df.sort_values(by=[award], ascending=False).head(n=1))\r\n",
    "    \r\n",
    "# pd.read_csv(baseloc+\"/award_percent.csv\")\r\n",
    "for award in tqdm(word_dict):\r\n",
    "    print(f\"{award} Award\")\r\n",
    "    total_per_df50 = total_per_df.sort_values(by=[\"관련 글/댓글 수\"], ascending=False).head(n=50)\r\n",
    "    print(total_per_df50.sort_values(by=[award], ascending=False).head(n=3))\r\n",
    "    print(\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bce65148f74d67986ffa856af5789e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "게이머 Award\n",
      "       Vtuber  관련 글/댓글 수        게이머        성희롱         나쁜말          중계  \\\n",
      "38  니노마에 이나니스        848  85.259434  55.542453  135.849057  280.778302   \n",
      "44    유우키 치히로        678  47.935103   8.849558   26.991150  112.831858   \n",
      "46     셀렌 타츠키        636  46.540881   6.289308   35.220126   71.226415   \n",
      "\n",
      "          호감       비호감        미인       못생김         꿀잼         노잼  \n",
      "38  3.419811  0.471698  5.306604  0.589623  18.160377  10.023585  \n",
      "44  0.737463  0.294985  0.442478  0.000000   2.949853   0.442478  \n",
      "46  7.547170  0.628931  2.830189  1.572327   3.301887   1.415094  \n",
      "\n",
      "\n",
      "성희롱 Award\n",
      "       Vtuber  관련 글/댓글 수        게이머         성희롱         나쁜말          중계  \\\n",
      "18    나키리 아야메       2214  12.646793  145.076784   38.211382   68.654020   \n",
      "0      사쿠라 미코       5438  11.456418   79.753586   25.947039  100.478117   \n",
      "38  니노마에 이나니스        848  85.259434   55.542453  135.849057  280.778302   \n",
      "\n",
      "          호감       비호감        미인       못생김         꿀잼         노잼  \n",
      "18  0.858175  0.496838  1.851852  0.225836   2.122855   1.400181  \n",
      "0   1.360794  0.147113  0.772343  0.257448   4.634057   1.158514  \n",
      "38  3.419811  0.471698  5.306604  0.589623  18.160377  10.023585  \n",
      "\n",
      "\n",
      "나쁜말 Award\n",
      "       Vtuber  관련 글/댓글 수        게이머         성희롱         나쁜말          중계  \\\n",
      "27    시로미야 미미       1335  27.415730   10.411985  140.749064  110.262172   \n",
      "38  니노마에 이나니스        848  85.259434   55.542453  135.849057  280.778302   \n",
      "18    나키리 아야메       2214  12.646793  145.076784   38.211382   68.654020   \n",
      "\n",
      "          호감       비호감        미인       못생김         꿀잼         노잼  \n",
      "27  0.823970  0.000000  1.498127  0.000000   2.696629   0.749064  \n",
      "38  3.419811  0.471698  5.306604  0.589623  18.160377  10.023585  \n",
      "18  0.858175  0.496838  1.851852  0.225836   2.122855   1.400181  \n",
      "\n",
      "\n",
      "중계 Award\n",
      "       Vtuber  관련 글/댓글 수        게이머        성희롱         나쁜말          중계  \\\n",
      "38  니노마에 이나니스        848  85.259434  55.542453  135.849057  280.778302   \n",
      "43     레인 패터슨        621  25.603865  26.409018   33.977456  145.088567   \n",
      "26    레오스 빈센트       1271  24.154209   6.923682   36.506688  138.867034   \n",
      "\n",
      "          호감       비호감        미인       못생김         꿀잼         노잼  \n",
      "38  3.419811  0.471698  5.306604  0.589623  18.160377  10.023585  \n",
      "43  1.771337  0.000000  0.805153  0.000000   5.152979   1.610306  \n",
      "26  5.428796  0.078678  0.157356  0.000000   6.766326   1.337530  \n",
      "\n",
      "\n",
      "호감 Award\n",
      "     Vtuber  관련 글/댓글 수        게이머       성희롱        나쁜말          중계        호감  \\\n",
      "46   셀렌 타츠키        636  46.540881  6.289308  35.220126   71.226415  7.547170   \n",
      "28   시시로 보탄       1177  24.553951  9.090909  20.050977   99.830076  5.437553   \n",
      "26  레오스 빈센트       1271  24.154209  6.923682  36.506688  138.867034  5.428796   \n",
      "\n",
      "         비호감        미인       못생김        꿀잼        노잼  \n",
      "46  0.628931  2.830189  1.572327  3.301887  1.415094  \n",
      "28  0.424809  1.104503  0.509771  4.078165  1.189465  \n",
      "26  0.078678  0.157356  0.000000  6.766326  1.337530  \n",
      "\n",
      "\n",
      "비호감 Award\n",
      "      Vtuber  관련 글/댓글 수        게이머        성희롱        나쁜말         중계        호감  \\\n",
      "47    군도 미레이        631  12.044374  17.908082  28.526149  25.198098  0.792393   \n",
      "46    셀렌 타츠키        636  46.540881   6.289308  35.220126  71.226415  7.547170   \n",
      "9   나츠이로 마츠리       3017  12.462711  18.462048  36.658933  58.800133  2.121313   \n",
      "\n",
      "         비호감        미인       못생김        꿀잼        노잼  \n",
      "47  0.792393  4.278922  0.475436  2.535658  1.584786  \n",
      "46  0.628931  2.830189  1.572327  3.301887  1.415094  \n",
      "9   0.563474  0.994365  0.364601  3.314551  1.193238  \n",
      "\n",
      "\n",
      "미인 Award\n",
      "       Vtuber  관련 글/댓글 수        게이머        성희롱         나쁜말          중계  \\\n",
      "38  니노마에 이나니스        848  85.259434  55.542453  135.849057  280.778302   \n",
      "25       IRyS       1422  11.251758   4.360056   22.714487   69.127989   \n",
      "47     군도 미레이        631  12.044374  17.908082   28.526149   25.198098   \n",
      "\n",
      "          호감       비호감        미인       못생김         꿀잼         노잼  \n",
      "38  3.419811  0.471698  5.306604  0.589623  18.160377  10.023585  \n",
      "25  1.054852  0.281294  4.781997  1.898734   1.969058   1.336146  \n",
      "47  0.792393  0.792393  4.278922  0.475436   2.535658   1.584786  \n",
      "\n",
      "\n",
      "못생김 Award\n",
      "      Vtuber  관련 글/댓글 수        게이머        성희롱        나쁜말          중계  \\\n",
      "25      IRyS       1422  11.251758   4.360056  22.714487   69.127989   \n",
      "46    셀렌 타츠키        636  46.540881   6.289308  35.220126   71.226415   \n",
      "33  네코마타 오카유        877  15.165336  17.673888  19.384265  108.323831   \n",
      "\n",
      "          호감       비호감        미인       못생김        꿀잼        노잼  \n",
      "25  1.054852  0.281294  4.781997  1.898734  1.969058  1.336146  \n",
      "46  7.547170  0.628931  2.830189  1.572327  3.301887  1.415094  \n",
      "33  2.964652  0.000000  3.192702  1.140251  5.131129  0.684151  \n",
      "\n",
      "\n",
      "꿀잼 Award\n",
      "       Vtuber  관련 글/댓글 수        게이머        성희롱         나쁜말          중계  \\\n",
      "38  니노마에 이나니스        848  85.259434  55.542453  135.849057  280.778302   \n",
      "40     오마루 폴카        751  16.644474  13.448735   22.902796   88.548602   \n",
      "26    레오스 빈센트       1271  24.154209   6.923682   36.506688  138.867034   \n",
      "\n",
      "          호감       비호감        미인       못생김         꿀잼         노잼  \n",
      "38  3.419811  0.471698  5.306604  0.589623  18.160377  10.023585  \n",
      "40  3.595206  0.000000  1.331558  0.532623   7.057257   1.331558  \n",
      "26  5.428796  0.078678  0.157356  0.000000   6.766326   1.337530  \n",
      "\n",
      "\n",
      "노잼 Award\n",
      "       Vtuber  관련 글/댓글 수        게이머        성희롱         나쁜말          중계  \\\n",
      "38  니노마에 이나니스        848  85.259434  55.542453  135.849057  280.778302   \n",
      "37        로보코        852  26.643192   8.098592   17.957746  107.511737   \n",
      "31     토키노 소라       1090  27.431193  12.201835   16.605505  100.091743   \n",
      "\n",
      "          호감       비호감        미인       못생김         꿀잼         노잼  \n",
      "38  3.419811  0.471698  5.306604  0.589623  18.160377  10.023585  \n",
      "37  0.234742  0.117371  1.291080  0.234742   3.051643   3.755869  \n",
      "31  0.366972  0.000000  1.284404  0.366972   3.119266   3.394495  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "output_filename='commentpost_rank.csv'\r\n",
    "total_commentpost_df=total_per_df.sort_values(by=[\"관련 글/댓글 수\"], ascending=False)[[\"Vtuber\",\"관련 글/댓글 수\"]]\r\n",
    "\r\n",
    "total_commentpost_df.index = np.arange(1, len(total_commentpost_df) + 1)\r\n",
    "\r\n",
    "try:\r\n",
    "    old_data = pd.read_csv(os.path.join(oldloc, output_filename))\r\n",
    "except:\r\n",
    "    old_data = pd.DataFrame()\r\n",
    "compared_ranks = []\r\n",
    "for idx, member in tqdm(total_commentpost_df.iterrows(), total=len(total_commentpost_df)):\r\n",
    "    vtuber = member[\"Vtuber\"]\r\n",
    "    try:\r\n",
    "        old_rank = old_data[old_data[\"Vtuber\"] == vtuber].index[0]+1\r\n",
    "    except:\r\n",
    "        old_rank = \"NA\"\r\n",
    "\r\n",
    "    if old_rank == \"NA\":\r\n",
    "        compared_rank = f\"NEW\"\r\n",
    "    elif idx > old_rank:\r\n",
    "        compared_rank = f\"▼{idx-old_rank}\"\r\n",
    "    elif idx < old_rank:\r\n",
    "        compared_rank = f\"▲{old_rank-idx}\"\r\n",
    "    elif idx == old_rank:\r\n",
    "        compared_rank = f\"■-\"\r\n",
    "    else:\r\n",
    "        compared_rank=\"Error\"\r\n",
    "    compared_ranks.append(compared_rank)\r\n",
    "\r\n",
    "total_commentpost_df[\"전월 대비 순위\"]=compared_ranks\r\n",
    "total_commentpost_df.to_csv(baseloc+'/commentpost_rank.csv', sep=',', index=True)\r\n",
    "\r\n",
    "print(total_commentpost_df.head(n=10))\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534e5a8d6acd42ea8b65e67481960ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       Vtuber  관련 글/댓글 수 전월 대비 순위\n",
      "1     아마네 카나타       5439      ▲32\n",
      "2      사쿠라 미코       5438       ■-\n",
      "3     우사다 페코라       5139       ■-\n",
      "4       호쇼 마린       4026       ▲1\n",
      "5     토코야미 토와       3946       ▲5\n",
      "6     아카이 하아토       3339      ▲25\n",
      "7    츠노마키 와타메       3230       ▲4\n",
      "8     아토리 코토코       3146      NEW\n",
      "9   호시마치 스이세이       3087       ▼1\n",
      "10   나츠이로 마츠리       3017      ▲19\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(sum(total_commentpost_df[\"관련 글/댓글 수\"]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "116355\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Youtube"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import re\r\n",
    "import urllib.parse as urlparse\r\n",
    "import requests\r\n",
    "from datetime import datetime\r\n",
    "import os\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "import ray\r\n",
    "ray.init()\r\n",
    "from gevent.pool import Pool\r\n",
    "\r\n",
    "# https://stackoverflow.com/questions/4356538/how-can-i-extract-video-id-from-youtubes-link-in-python\r\n",
    "def video_id_parse(value):\r\n",
    "    \"\"\"\r\n",
    "    Examples:\r\n",
    "    - http://youtu.be/SA2iWivDJiE\r\n",
    "    - http://www.youtube.com/watch?v=_oPAwA_Udwc&feature=feedu\r\n",
    "    - http://www.youtube.com/embed/SA2iWivDJiE\r\n",
    "    - http://www.youtube.com/v/SA2iWivDJiE?version=3&amp;hl=en_US\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    query = urlparse.urlparse(value)\r\n",
    "    if query.hostname == 'youtu.be':\r\n",
    "        return query.path[1:]\r\n",
    "    if query.hostname in ('www.youtube.com', 'youtube.com'):\r\n",
    "        if query.path == '/watch':\r\n",
    "            p = urlparse.parse_qs(query.query)\r\n",
    "            return p['v'][0]\r\n",
    "        if query.path[:7] == '/embed/':\r\n",
    "            return query.path.split('/')[2]\r\n",
    "        if query.path[:3] == '/v/':\r\n",
    "            return query.path.split('/')[2]\r\n",
    "    # fail?\r\n",
    "    return None\r\n",
    "\r\n",
    "gall = 'kizunaai';year=datetime.now().year; month =datetime.now().month-1 # 갤러리, 연, 월\r\n",
    "baseloc = os.path.abspath('./%s/%s/%s/' % (gall,year,month)) # 경로\r\n",
    "  # https://stackoverflow.com/questions/28292822/how-to-know-uploader-of-a-video-using-youtube-v3-api\r\n",
    "youtube_query='https://www.googleapis.com/youtube/v3/videos?fields=items(snippet(channelTitle))&part=snippet&id={YOUR_VIDEO_ID}&key={API_KEY}'\r\n",
    "# https://stackoverflow.com/questions/4705996/python-regex-convert-youtube-url-to-youtube-video/19161373\r\n",
    "# Regex\r\n",
    "yt_regex = r'(https?://)?(www\\.)?(youtube|youtu|youtube-nocookie)\\.(com|be)/(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})'\r\n",
    "\r\n",
    "columns=[\"ChannelName\", \"VideoID\", \"Count\"]\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-02 08:54:06,944\tINFO services.py:1245 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\r\n",
    "try:\r\n",
    "    cont[\"제목내용\"]=cont[u'제목'].astype(str)+'\\n'+cont['content'].astype(str)\r\n",
    "    yout_cont = cont[cont['제목내용'].str.contains(yt_regex, na=False, regex = True)][['제목내용']]\r\n",
    "except NameError as e:\r\n",
    "    idf = pd.read_json(baseloc+'post.json');cdf = pd.read_json(baseloc+'comment.json')\r\n",
    "    cdf=cdf[cdf['dccon']==False]\r\n",
    "    cont = pd.concat([idf, cdf],sort=False)\r\n",
    "    cont[\"제목내용\"]=cont[u'제목'].astype(str)+'\\n'+cont['content'].astype(str)\r\n",
    "    yout_cont = cont[cont['제목내용'].str.contains(\"(youtube)|(youtu.be)\", na=False, regex = True)][['제목내용']]\r\n",
    "if os.path.isfile(baseloc+'/youtube.csv'):\r\n",
    "    yt_df=pd.read_csv(baseloc+'/youtube.csv',index_col=None)\r\n",
    "    yt_df[\"VideoID\"]=yt_df[\"VideoID\"].str.replace(r\"[가-힣|ㄱ-ㅎ|ㅏ-ㅣ ]+\",\"\",regex=True).str.replace(r\"(https://www.youtube.com/watch)|(https://m.youtube.com/watch)\",\"\",regex=True)\r\n",
    "    yt_df[\"Count\"]=0\r\n",
    "else:\r\n",
    "    yt_df=pd.DataFrame(columns=columns)\r\n",
    "\r\n",
    "yout_cont[\"제목내용\"]=yout_cont[\"제목내용\"].str.replace(r'<[^<]+?>','',regex=True)\r\n",
    "req_count=0\r\n",
    "NUM=0\r\n",
    "\r\n",
    "yt_regex_id = ray.put(yt_regex)\r\n",
    "@ray.remote\r\n",
    "def parse_contents(contents, yt_regex):\r\n",
    "    processed_video_ids = []\r\n",
    "    for content in contents:\r\n",
    "        content=str(content)\r\n",
    "        video_ids = [x.group() for x in re.finditer(yt_regex, content)]\r\n",
    "        \r\n",
    "        for raw_video_id in video_ids:\r\n",
    "            video_id = str(video_id_parse(str(raw_video_id)))\r\n",
    "            if video_id is None:\r\n",
    "                continue\r\n",
    "            video_id = video_id.replace(\"https://www.youtube.com/watch\",\"\").replace(\"https://m.youtube.com/watch\",\"\")\r\n",
    "            video_id = re.sub(r\"[가-힣|ㄱ-ㅎ|ㅏ-ㅣ ]+\",\"\",video_id)\r\n",
    "            processed_video_ids.append([video_id])\r\n",
    "            \r\n",
    "    return processed_video_ids\r\n",
    "\r\n",
    "result_ids=[]\r\n",
    "contents = []\r\n",
    "batch_size = 1000\r\n",
    "for idx, row in tqdm(yout_cont.iterrows(), total=len(yout_cont)):\r\n",
    "    content = row[\"제목내용\"]\r\n",
    "    contents.append(content)\r\n",
    "    if len(contents) >= batch_size:\r\n",
    "        result_ids.append(parse_contents.remote(contents, yt_regex_id))\r\n",
    "        contents=[]\r\n",
    "    \r\n",
    "with tqdm(total=len(result_ids)) as pbar: # 소요 시간 출력\r\n",
    "    yt_arr = []\r\n",
    "    while len(result_ids):\r\n",
    "        done_id, result_ids = ray.wait(result_ids)\r\n",
    "        test=ray.get(done_id)\r\n",
    "\r\n",
    "        video_ids = test[0]\r\n",
    "        yt_arr.extend(video_ids)\r\n",
    "        pbar.update(1)\r\n",
    "        \r\n",
    "raw_yt_df=pd.DataFrame(yt_arr, columns=[\"VideoID\"])\r\n",
    "raw_yt_df = raw_yt_df[raw_yt_df[\"VideoID\"] != \"None\"]\r\n",
    "yt_df=raw_yt_df.value_counts().to_frame(name=\"Count\")\r\n",
    "\r\n",
    "yt_df.sort_values(by=['Count'], ascending=False, inplace=True)\r\n",
    "yt_df.to_csv(baseloc+'/youtube.csv', sep=',')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-c346f438c2ad>:3: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  yout_cont = cont[cont['제목내용'].str.contains(yt_regex, na=False, regex = True)][['제목내용']]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e804e3d84f44e999818eda740decf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/187071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa80b368282e440ea7557401bd044f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/187 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Index(...) must be called with a collection of some kind, 'VideoID' was passed",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c346f438c2ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mraw_yt_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"VideoID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;31m# yt_df.sort_values(by=['Count'], ascending=False, inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# yt_df.to_csv(baseloc+'/youtube.csv',index=False, sep=',')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/helloworld/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    691\u001b[0m                         \u001b[0;31m# \"Collection[Any]\"; expected \"Union[Union[Union[ExtensionArray,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                         \u001b[0;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[1;32m    695\u001b[0m                         \u001b[0;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/helloworld/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   6335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6337\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/helloworld/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_data_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__array__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, 'VideoID' was passed"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "yt_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Unknown 재탐색\r\n",
    "yt_df=pd.read_csv(baseloc+'/youtube.csv',index_col=None)\r\n",
    "KEYS=[\"PUT_YOUR_API_KEY\"]\r\n",
    "\r\n",
    "@ray.remote\r\n",
    "def getChannelName(idx, video_id, key):\r\n",
    "    try:\r\n",
    "        youtube_info = requests.get(youtube_query.format(YOUR_VIDEO_ID=video_id, API_KEY=key)).json()\r\n",
    "        channel_name = youtube_info['items'][0]['snippet']['channelTitle']\r\n",
    "    except:\r\n",
    "        channel_name = \"Unknown\"\r\n",
    "    return idx, channel_name\r\n",
    "    \r\n",
    "req_count = 0\r\n",
    "NUM = 0\r\n",
    "result_ids = []\r\n",
    "for idx, row in tqdm(yt_df.iterrows(), total=len(yt_df)):\r\n",
    "    channel_name=str(row[\"ChannelName\"])\r\n",
    "    if channel_name == \"Unknown\":\r\n",
    "        video_id = str(row[\"VideoID\"])\r\n",
    "        if req_count > 9000:\r\n",
    "            NUM+=1\r\n",
    "            req_count=0\r\n",
    "        req_count+=1\r\n",
    "\r\n",
    "        result_ids.append(getChannelName.remote(idx, video_id, KEYS[idx%len(KEYS)]))\r\n",
    "\r\n",
    "\r\n",
    "while len(result_ids):\r\n",
    "    done_id, result_ids = ray.wait(result_ids)\r\n",
    "    test=ray.get(done_id)\r\n",
    "#     print(test)\r\n",
    "# out: [(31, 'Unknown')]\r\n",
    "\r\n",
    "    idx, channel_name = test[0]\r\n",
    "    yt_df.loc[idx,'ChannelName'] = channel_name\r\n",
    "\r\n",
    "yt_df.to_csv(baseloc+'/youtube.csv',index=False, sep=',')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8714bc14a0574556813bcbc6dca231b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(31, 'Unknown')]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c2212e663039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0myt_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ChannelName'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(yt_df.head(n=10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"total number of post: {idf['번호'].count()}\")\n",
    "print(idf.sort_values(by=['추천 수'], ascending=False).head(n=1))\n",
    "print(\"\\n\")\n",
    "print(idf.sort_values(by=['조회 수'], ascending=False).head(n=1))\n",
    "print(\"\\n\")\n",
    "print(idf.sort_values(by=['달린 댓글 수'], ascending=False).head(n=1))\n",
    "print(\"\\n\")\n",
    "print(idf[\"개념글 수\"].value_counts())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}